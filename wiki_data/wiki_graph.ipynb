{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a53670-d130-4889-9d3c-10059b54916a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install langchain openai wikipedia tiktoken neo4j python-dotenv transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e31c631-7ae8-4f97-921f-1651daceb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, json\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"wikipedia\")\n",
    "\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores.neo4j_vector import SearchType\n",
    "\n",
    "from py2neo import Graph\n",
    "from neo4j import GraphDatabase\n",
    "from graphdatascience import GraphDataScience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6776f3e-1bc5-43c5-acfe-0358d6b8717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://3.35.174.93:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"password\"\n",
    "graph = Graph(uri, auth=(username, password))\n",
    "gds = GraphDataScience(\n",
    "    uri,\n",
    "    auth=(username, password),\n",
    "    aura_ds=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2678b13-eb75-429e-8370-90a5cf3390f3",
   "metadata": {},
   "source": [
    "### 모듈 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd1a0421-b30a-40a1-b114-dd033dae28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=boto3_bedrock, region_name='us-east-1')\n",
    "\n",
    "# Neo4j 데이터 초기화\n",
    "def init_graph_data():\n",
    "    graph.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "def bert_len(text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    tokens = tokenizer.encode(text, max_length=512, truncation=True)\n",
    "    return len(tokens)\n",
    "\n",
    "# wikipedia 문서 로드 및 chunk 단위로 Split\n",
    "def chunk_document(query, chunk_size, chunk_overlap):\n",
    "    raw_documents = WikipediaLoader(query=query, doc_content_chars_max=20000, load_max_docs=1).load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "              chunk_size = chunk_size,\n",
    "              chunk_overlap  = chunk_overlap,\n",
    "              length_function = bert_len,\n",
    "              separators=['\\n\\n', '\\n', ' ', ''],\n",
    "          )\n",
    "    documents = text_splitter.create_documents([raw_documents[0].page_content])\n",
    "    return documents\n",
    "\n",
    "def chunk_text(query, chunk_size, chunk_overlap):\n",
    "    raw_documents = WikipediaLoader(query=query, doc_content_chars_max=20000, load_max_docs=1).load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "              chunk_size = chunk_size,\n",
    "              chunk_overlap  = chunk_overlap,\n",
    "              length_function = bert_len,\n",
    "              separators=['\\n\\n', '\\n', ' ', ''],\n",
    "          )\n",
    "    documents = text_splitter.split_text(raw_documents[0].page_content)\n",
    "    return documents\n",
    "\n",
    "\n",
    "# embedding을 graph에 로드\n",
    "def vector_load(text):\n",
    "    neo4j_vector = Neo4jVector.from_documents(\n",
    "        text,\n",
    "        bedrock_embeddings,\n",
    "        url=uri,\n",
    "        username=username,\n",
    "        password=password\n",
    "    )\n",
    "    return neo4j_vector\n",
    "\n",
    "# vector 검색 결과 확인\n",
    "def search_context(neo4j_vector, question):\n",
    "    vector_results = neo4j_vector.similarity_search(question, k=1)\n",
    "    vector_result = vector_results[0].page_content\n",
    "    return vector_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f100d-525c-4006-9e72-ae6d927174d2",
   "metadata": {},
   "source": [
    "### chunk size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c32fec2-292f-4222-8c13-e9e97663fdd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_graph_data()\n",
    "\n",
    "query = \"Amazon S3\"\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 30\n",
    "\n",
    "docs = chunk_document(query, chunk_size, chunk_overlap)\n",
    "long_vector = vector_load(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f4b8a9-1c40-4ce9-987a-79ada85311e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon S3 or Amazon Simple Storage Service is a service offered by Amazon Web Services (AWS) that provides object storage through a web service interface. Amazon S3 uses the same scalable storage infrastructure that Amazon.com uses to run its e-commerce network. Amazon S3 can store any type of object, which allows uses like storage for Internet applications, backups, disaster recovery, data archives, data lakes for analytics, and hybrid cloud storage. AWS launched Amazon S3 in the United States on March 14, 2006, then in Europe in November 2007.\n",
      "\n",
      "\n",
      "== Technical details ==\n",
      "\n",
      "\n",
      "=== Design ===\n",
      "Amazon S3 manages data with an object storage architecture which aims to provide scalability, high availability, and low latency with high durability. The basic storage units of Amazon S3 are objects which are organized into buckets. Each object is identified by a unique, user-assigned key. Buckets can be managed using the console provided by Amazon S3, programmatically with the AWS SDK, or the REST application programming interface. Objects can be up to five terabytes in size. Requests are authorized using an access control list associated with each object bucket and support versioning which is disabled by default. Since buckets are typically the size of an entire file system mount in other systems, this access control scheme is very coarse-grained. In other words, unique access controls cannot be associated with individual files. Amazon S3 can be used to replace static web-hosting infrastructure with HTTP client-accessible objects, index document support, and error document support.\n",
      "The Amazon AWS authentication mechanism allows the creation of authenticated URLs, valid for a specified amount of time. Every item in a bucket can also be served as a BitTorrent feed. The Amazon S3 store can act as a seed host for a torrent and any BitTorrent client can retrieve the file. This can drastically reduce the bandwidth cost for the download of popular objects. A bucket can be configured to save HTTP log information to a sibling bucket; this can be used in data mining operations. There are various User Mode File System (FUSE)–based file systems for Unix-like operating systems (for example, Linux) that can be used to mount an S3 bucket as a file system. The semantics of the Amazon S3 file system are not that of a POSIX file system, so the file system may not behave entirely as expected.\n",
      "\n",
      "\n",
      "=== Amazon S3 storage classes ===\n",
      "Amazon S3 offers nine different storage classes with different levels of durability, availability, and performance requirements.\n",
      "Amazon S3 Standard is the default. It is general purpose storage for frequently accessed data.\n",
      "Amazon S3 Express One Zone is a single-digit millisecond latency storage for frequently accessed data and latency-sensitive applications. It stores data only in one availability zone.\n",
      "Amazon S3 Standard-Infrequent Access (Standard-IA) is designed for less frequently accessed data, such as backups and disaster recovery data.\n",
      "Amazon S3 One Zone-Infrequent Access (One Zone-IA) performs like the Standard-IA, but stores data only in one availability zone.\n",
      "Amazon S3 Intelligent-Tiering moves objects automatically to a more cost-efficient storage class.\n",
      "Amazon S3 on Outposts brings storage to installations not hosted by Amazon.\n",
      "Amazon S3 Glacier Instant Retrieval is a low-cost storage for rarely accessed data, but which still requires rapid retrieval.\n",
      "Amazon S3 Glacier Flexible Retrieval is also a low-cost option for long-lived data; it offers 3 retrieval speeds, ranging from minutes to hours.\n",
      "Amazon S3 Glacier Deep Archive is the lowest cost storage for long-lived archive data that is accessed less than once per year and is retrieved asynchronously.The Amazon S3 Glacier storage classes above are distinct from Amazon Glacier, which is a separate product with its own APIs.\n",
      "\n",
      "\n",
      "=== File size limits ===\n",
      "An object in S3 can be between 0 bytes and 5TB. If an object is larger than 5TB, it must be divided into chunks prior to uploading. When uploading, Amazon S3 allows a maximum of 5GB in a single upload operation; hence, objects larger than 5GB must be uploaded via the S3 multipart upload API.\n",
      "\n",
      "\n",
      "== Uses ==\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the different storage classes offered by Amazon S3? Please provide a list of all available storage classes.\"\n",
    "print(search_context(long_vector, question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126aef54-e80b-4e36-b71b-a5695a60fd03",
   "metadata": {},
   "source": [
    "### chunk size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6698747-205e-4495-a7ce-417e8575eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_graph_data()\n",
    "\n",
    "query = \"Amazon S3\"\n",
    "chunk_size = 200\n",
    "chunk_overlap = 30\n",
    "\n",
    "docs = chunk_document(query, chunk_size, chunk_overlap)\n",
    "short_vector = vector_load(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88fada6-7fc8-4d7c-bb77-cd071fb66c2b",
   "metadata": {},
   "source": [
    "<img src=\"./image/chunks.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45504d-e6eb-4d27-9f3f-c2f8b3338e5e",
   "metadata": {},
   "source": [
    "#### 불완전한 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "208c9477-cc11-45d9-8d84-aa94d092cc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Amazon S3 storage classes ===\n",
      "Amazon S3 offers nine different storage classes with different levels of durability, availability, and performance requirements.\n",
      "Amazon S3 Standard is the default. It is general purpose storage for frequently accessed data.\n",
      "Amazon S3 Express One Zone is a single-digit millisecond latency storage for frequently accessed data and latency-sensitive applications. It stores data only in one availability zone.\n",
      "Amazon S3 Standard-Infrequent Access (Standard-IA) is designed for less frequently accessed data, such as backups and disaster recovery data.\n",
      "Amazon S3 One Zone-Infrequent Access (One Zone-IA) performs like the Standard-IA, but stores data only in one availability zone.\n"
     ]
    }
   ],
   "source": [
    "print(search_context(short_vector, question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd6147-9b4c-491c-b5fe-87d01eded523",
   "metadata": {},
   "source": [
    "### Chunk 단위 임베딩으로 그래프 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c9d461e-ac5e-4241-8a78-db0380cc8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(xs, n=3):\n",
    "    n = max(1, n)\n",
    "    return [xs[i:i + n] for i in range(0, len(xs), n)]\n",
    "    \n",
    "def create_text_embedding_entries(query, chunk_size, chunk_overlap):\n",
    "    docs = chunk_text(query, chunk_size, chunk_overlap)\n",
    "    service_name = query\n",
    "    res = []    \n",
    "    seq_id = -1\n",
    "    \n",
    "    for d in chunks(docs):\n",
    "        embeddings = bedrock_embeddings.embed_documents(d)\n",
    "        for i in range(len(d)):\n",
    "            seq_id += 1\n",
    "            res.append({'name': service_name,\n",
    "                        'seqId': seq_id,\n",
    "                        'contextId': service_name + str(seq_id),  # unique \n",
    "                        'textEmbedding': embeddings[i],  # chunked\n",
    "                        'text': d[i]  })\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca8bf483-216b-4623-85bf-ddf135fcaa9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>seqId</th>\n",
       "      <th>contextId</th>\n",
       "      <th>textEmbedding</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon S3</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon S30</td>\n",
       "      <td>[0.9296875, -0.48632812, 0.61328125, -0.230468...</td>\n",
       "      <td>Amazon S3 or Amazon Simple Storage Service is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon S3</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon S31</td>\n",
       "      <td>[0.6953125, 0.47460938, -0.26757812, 0.5429687...</td>\n",
       "      <td>=== Design ===</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon S3</td>\n",
       "      <td>2</td>\n",
       "      <td>Amazon S32</td>\n",
       "      <td>[0.35351562, -0.29492188, 0.5625, -0.13378906,...</td>\n",
       "      <td>Amazon S3 manages data with an object storage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon S3</td>\n",
       "      <td>3</td>\n",
       "      <td>Amazon S33</td>\n",
       "      <td>[0.07080078, -0.28125, 0.5546875, -0.4296875, ...</td>\n",
       "      <td>The Amazon AWS authentication mechanism allows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon S3</td>\n",
       "      <td>4</td>\n",
       "      <td>Amazon S34</td>\n",
       "      <td>[0.09277344, -0.31640625, 0.4296875, -0.455078...</td>\n",
       "      <td>=== Amazon S3 storage classes ===\\nAmazon S3 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon S3</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazon S35</td>\n",
       "      <td>[0.46679688, -0.48828125, 0.6875, -0.10107422,...</td>\n",
       "      <td>Amazon S3 Intelligent-Tiering moves objects au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amazon S3</td>\n",
       "      <td>6</td>\n",
       "      <td>Amazon S36</td>\n",
       "      <td>[0.2578125, -0.20019531, 0.62890625, -0.470703...</td>\n",
       "      <td>=== File size limits ===\\nAn object in S3 can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amazon S3</td>\n",
       "      <td>7</td>\n",
       "      <td>Amazon S37</td>\n",
       "      <td>[0.62890625, -0.40429688, 0.55859375, -0.31640...</td>\n",
       "      <td>=== Notable users ===\\nPhoto hosting service S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amazon S3</td>\n",
       "      <td>8</td>\n",
       "      <td>Amazon S38</td>\n",
       "      <td>[0.6015625, -0.578125, 0.21289062, -0.16992188...</td>\n",
       "      <td>Reddit is hosted on Amazon S3.\\nBitcasa, and T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amazon S3</td>\n",
       "      <td>9</td>\n",
       "      <td>Amazon S39</td>\n",
       "      <td>[0.6171875, -0.47460938, 0.70703125, -0.371093...</td>\n",
       "      <td>=== S3 API and competing services ===\\nThe bro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  seqId   contextId  \\\n",
       "0  Amazon S3      0  Amazon S30   \n",
       "1  Amazon S3      1  Amazon S31   \n",
       "2  Amazon S3      2  Amazon S32   \n",
       "3  Amazon S3      3  Amazon S33   \n",
       "4  Amazon S3      4  Amazon S34   \n",
       "5  Amazon S3      5  Amazon S35   \n",
       "6  Amazon S3      6  Amazon S36   \n",
       "7  Amazon S3      7  Amazon S37   \n",
       "8  Amazon S3      8  Amazon S38   \n",
       "9  Amazon S3      9  Amazon S39   \n",
       "\n",
       "                                       textEmbedding  \\\n",
       "0  [0.9296875, -0.48632812, 0.61328125, -0.230468...   \n",
       "1  [0.6953125, 0.47460938, -0.26757812, 0.5429687...   \n",
       "2  [0.35351562, -0.29492188, 0.5625, -0.13378906,...   \n",
       "3  [0.07080078, -0.28125, 0.5546875, -0.4296875, ...   \n",
       "4  [0.09277344, -0.31640625, 0.4296875, -0.455078...   \n",
       "5  [0.46679688, -0.48828125, 0.6875, -0.10107422,...   \n",
       "6  [0.2578125, -0.20019531, 0.62890625, -0.470703...   \n",
       "7  [0.62890625, -0.40429688, 0.55859375, -0.31640...   \n",
       "8  [0.6015625, -0.578125, 0.21289062, -0.16992188...   \n",
       "9  [0.6171875, -0.47460938, 0.70703125, -0.371093...   \n",
       "\n",
       "                                                text  \n",
       "0  Amazon S3 or Amazon Simple Storage Service is ...  \n",
       "1                                     === Design ===  \n",
       "2  Amazon S3 manages data with an object storage ...  \n",
       "3  The Amazon AWS authentication mechanism allows...  \n",
       "4  === Amazon S3 storage classes ===\\nAmazon S3 o...  \n",
       "5  Amazon S3 Intelligent-Tiering moves objects au...  \n",
       "6  === File size limits ===\\nAn object in S3 can ...  \n",
       "7  === Notable users ===\\nPhoto hosting service S...  \n",
       "8  Reddit is hosted on Amazon S3.\\nBitcasa, and T...  \n",
       "9  === S3 API and competing services ===\\nThe bro...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Amazon S3'\n",
    "vector = create_text_embedding_entries(query, chunk_size, chunk_overlap)\n",
    "pd.DataFrame(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc1ee9-b205-4391-bd90-172b408d878b",
   "metadata": {},
   "source": [
    "### -임베딩 Vector 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7acf7cea-fcdd-4608-ad39-158a8d76e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_embeddings(emb):\n",
    "    total = len(emb)\n",
    "    count = 0\n",
    "    for d in chunks(emb, 100):\n",
    "        gds.run_cypher('''\n",
    "        UNWIND $records AS record\n",
    "        MERGE(s:Service {name:record.name})\n",
    "        CREATE(c:Chunk {chunkid:record.contextId, seqid:record.seqId, text:record.text})\n",
    "        MERGE(s)-[:CHUNKED]->(c)\n",
    "        with c, record\n",
    "        CALL db.create.setVectorProperty(c, 'embedding', record.textEmbedding)\n",
    "        YIELD node\n",
    "        RETURN distinct 'done'\n",
    "        ''', params = {'records':d})\n",
    "        count += len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a64e3cd-e5ea-4bc2-a15d-36400eeb9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_graph_data()\n",
    "update_embeddings(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa25176-1f14-4191-b2da-28cbbb37bf73",
   "metadata": {},
   "source": [
    "<img src=\"./image/embed.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5826bf20-c786-4b5b-8c11-2eddebc419a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.chat_models import BedrockChat\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21831a7-f91a-4eab-871f-b741ba1eb28e",
   "metadata": {},
   "source": [
    "### -Without RAG\n",
    "학습 시점에 제공된 Public 정보를 활용. \n",
    "\n",
    "Outdated 된 정보를 제공하거나 Hallucination 발생할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31196b4d-6420-4dd9-adde-e78ebf10a5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Amazon S3 offers the following storage classes:\n",
      "\n",
      "- S3 Standard - High durability and availability for frequently accessed data. This is the default storage class.\n",
      "\n",
      "- S3 Standard-Infrequent Access (S3 Standard-IA) - For data that is less frequently accessed but requires high availability when needed. Lower storage price than S3 Standard but charges retrieval fees.\n",
      "\n",
      "- S3 One Zone-Infrequent Access (S3 One Zone-IA) - Same as S3 Standard-IA but stores data in a single Availability Zone. Lower cost but less availability guarantees.\n",
      "\n",
      "- S3 Intelligent-Tiering - Automatically moves data between four access tiers based on changing access patterns to optimize costs.\n",
      "\n",
      "- S3 Glacier Instant Retrieval - Low cost storage for archiving with milliseconds retrieval time.\n",
      "\n",
      "- S3 Glacier Flexible Retrieval - Archival storage where data retrieval time ranges from minutes to hours. Lowest cost.\n",
      "\n",
      "- S3 Glacier Deep Archive - Lowest cost storage class for long term archival with retrieval times of 12 hours.\n",
      "\n",
      "- S3 Outposts - S3 on AWS Outposts for storing data on premises.\n",
      "\n",
      "So in summary - Standard, Standard-IA, One Zone-IA, Intelligent-Tiering, Glacier Instant/Flexible/Deep, and Outposts.\n"
     ]
    }
   ],
   "source": [
    "boto3_bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2:1\", client=boto3_bedrock, model_kwargs={'max_tokens_to_sample':10240, \"temperature\": 0})\n",
    "\n",
    "answer = llm(\"What are the different storage classes offered by Amazon S3? Please provide a list of all available storage classes.\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a363f607-f4b8-40dd-b0a2-45afefe8e6fa",
   "metadata": {},
   "source": [
    "### -Vector 검색으로 Context 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9371d-df11-42b7-801e-3966e9103138",
   "metadata": {},
   "source": [
    "embedding을 검색하기 위한 'vector' 인덱스가 자동으로 생성되어 있으며, 인덱스를 활용해 빠르게 검색합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1aa9cb4-4879-4a74-8463-a323ce8024ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search = \"\"\"\n",
    "WITH $embedding AS e\n",
    "CALL db.index.vector.queryNodes('vector', $k, e) yield node, score\n",
    "RETURN node.text AS result\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af9d89d2-463a-42dd-a70d-d95f9fe517bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_instance = Neo4jGraph(url=uri, username=username, password=password)\n",
    "\n",
    "question = \"What are the different storage classes offered by Amazon S3? Please provide a list of all available storage classes.\"\n",
    "embedding = bedrock_embeddings.embed_query(question)\n",
    "context = graph_instance.query(\n",
    "    vector_search, {'embedding': embedding, 'k': 3})\n",
    "context = [el['result'] for el in context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcaca71f-aac7-4183-aa8a-66f562c18779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['=== Amazon S3 storage classes ===\\nAmazon S3 offers nine different storage classes with different levels of durability, availability, and performance requirements.\\nAmazon S3 Standard is the default. It is general purpose storage for frequently accessed data.\\nAmazon S3 Express One Zone is a single-digit millisecond latency storage for frequently accessed data and latency-sensitive applications. It stores data only in one availability zone.\\nAmazon S3 Standard-Infrequent Access (Standard-IA) is designed for less frequently accessed data, such as backups and disaster recovery data.\\nAmazon S3 One Zone-Infrequent Access (One Zone-IA) performs like the Standard-IA, but stores data only in one availability zone.', 'Amazon S3 manages data with an object storage architecture which aims to provide scalability, high availability, and low latency with high durability. The basic storage units of Amazon S3 are objects which are organized into buckets. Each object is identified by a unique, user-assigned key. Buckets can be managed using the console provided by Amazon S3, programmatically with the AWS SDK, or the REST application programming interface. Objects can be up to five terabytes in size. Requests are authorized using an access control list associated with each object bucket and support versioning which is disabled by default. Since buckets are typically the size of an entire file system mount in other systems, this access control scheme is very coarse-grained. In other words, unique access controls cannot be associated with individual files. Amazon S3 can be used to replace static web-hosting infrastructure with HTTP client-accessible objects, index document support, and error document support.', 'Amazon S3 or Amazon Simple Storage Service is a service offered by Amazon Web Services (AWS) that provides object storage through a web service interface. Amazon S3 uses the same scalable storage infrastructure that Amazon.com uses to run its e-commerce network. Amazon S3 can store any type of object, which allows uses like storage for Internet applications, backups, disaster recovery, data archives, data lakes for analytics, and hybrid cloud storage. AWS launched Amazon S3 in the United States on March 14, 2006, then in Europe in November 2007.\\n\\n\\n== Technical details ==']\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae294e8-e919-4550-aa74-1356e7e6a50f",
   "metadata": {},
   "source": [
    "### -답변 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "552c1b66-91e5-4933-bf81-f3b57edd9404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a helpful, respectful, and honest assistant, dedicated to providing valuable and accurate information.\n",
    "Guidance for answers below\n",
    "    Answer the question only using the in the context given below, and not with the prior knowledge.\n",
    "    If you don't see answer in the context just Reply \"Sorry , the answer is not in the context so I don't know\".\n",
    "\n",
    "Now read this context and answer the question. \n",
    "{context}\n",
    "\n",
    "Based on the provided context above and information from the retriever source, provide a detailed answer to the below question\n",
    "{question}\n",
    "\n",
    "If the information is not available in the context , respond with \"don't know.\"\n",
    "\n",
    "Assistant: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da3804-f9a8-4952-995f-5776a79a300f",
   "metadata": {},
   "source": [
    "### -불완전한 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7566fa4c-5fa9-4bf4-a222-4f7b8bc67fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the context provided, the different storage classes offered by Amazon S3 are:\n",
      "\n",
      "- Amazon S3 Standard\n",
      "- Amazon S3 Express One Zone  \n",
      "- Amazon S3 Standard-Infrequent Access (Standard-IA)\n",
      "- Amazon S3 One Zone-Infrequent Access (One Zone-IA)\n",
      "\n",
      "The context states that \"Amazon S3 offers nine different storage classes with different levels of durability, availability, and performance requirements.\" However, it only lists out the four storage classes mentioned above. Since the full list of nine storage classes is not provided in the context, I do not have enough information to provide the complete list.\n"
     ]
    }
   ],
   "source": [
    "answer = llm(prompt.format(context=context, question=question))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7814b81-b986-46dc-b2fd-6da92bea3727",
   "metadata": {},
   "source": [
    "### -Parent Document Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "875766cc-c076-47d1-9f36-95af9f962188",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search = \"\"\"\n",
    "WITH $embedding AS e\n",
    "CALL db.index.vector.queryNodes('vector', $k, e) yield node, score\n",
    "MATCH (s:Service)-[:CHUNKED]->(node)\n",
    "WITH s\n",
    "MATCH (s)-[:CHUNKED]->(docs:Chunk)\n",
    "WITH s, docs\n",
    "ORDER BY docs.seqid ASC\n",
    "RETURN s AS service, COLLECT(docs.text) AS result\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8322ca10-cac9-40f1-8bc2-baa338be1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_instance = Neo4jGraph(url=uri, username=username, password=password)\n",
    "\n",
    "question = \"What are the different storage classes offered by Amazon S3? Please provide a list of all available storage classes.\"\n",
    "embedding = bedrock_embeddings.embed_query(question)\n",
    "context = graph_instance.query(\n",
    "    vector_search, {'embedding': embedding, 'k': 1})\n",
    "context = [el['result'] for el in context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2adb6a2b-8c3f-4b3a-b2c7-112942230cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Amazon S3 or Amazon Simple Storage Service is a service offered by Amazon Web Services (AWS) that provides object storage through a web service interface. Amazon S3 uses the same scalable storage infrastructure that Amazon.com uses to run its e-commerce network. Amazon S3 can store any type of object, which allows uses like storage for Internet applications, backups, disaster recovery, data archives, data lakes for analytics, and hybrid cloud storage. AWS launched Amazon S3 in the United States on March 14, 2006, then in Europe in November 2007.\\n\\n\\n== Technical details ==',\n",
       "  '=== Design ===',\n",
       "  'Amazon S3 manages data with an object storage architecture which aims to provide scalability, high availability, and low latency with high durability. The basic storage units of Amazon S3 are objects which are organized into buckets. Each object is identified by a unique, user-assigned key. Buckets can be managed using the console provided by Amazon S3, programmatically with the AWS SDK, or the REST application programming interface. Objects can be up to five terabytes in size. Requests are authorized using an access control list associated with each object bucket and support versioning which is disabled by default. Since buckets are typically the size of an entire file system mount in other systems, this access control scheme is very coarse-grained. In other words, unique access controls cannot be associated with individual files. Amazon S3 can be used to replace static web-hosting infrastructure with HTTP client-accessible objects, index document support, and error document support.',\n",
       "  'The Amazon AWS authentication mechanism allows the creation of authenticated URLs, valid for a specified amount of time. Every item in a bucket can also be served as a BitTorrent feed. The Amazon S3 store can act as a seed host for a torrent and any BitTorrent client can retrieve the file. This can drastically reduce the bandwidth cost for the download of popular objects. A bucket can be configured to save HTTP log information to a sibling bucket; this can be used in data mining operations. There are various User Mode File System (FUSE)–based file systems for Unix-like operating systems (for example, Linux) that can be used to mount an S3 bucket as a file system. The semantics of the Amazon S3 file system are not that of a POSIX file system, so the file system may not behave entirely as expected.',\n",
       "  '=== Amazon S3 storage classes ===\\nAmazon S3 offers nine different storage classes with different levels of durability, availability, and performance requirements.\\nAmazon S3 Standard is the default. It is general purpose storage for frequently accessed data.\\nAmazon S3 Express One Zone is a single-digit millisecond latency storage for frequently accessed data and latency-sensitive applications. It stores data only in one availability zone.\\nAmazon S3 Standard-Infrequent Access (Standard-IA) is designed for less frequently accessed data, such as backups and disaster recovery data.\\nAmazon S3 One Zone-Infrequent Access (One Zone-IA) performs like the Standard-IA, but stores data only in one availability zone.',\n",
       "  'Amazon S3 Intelligent-Tiering moves objects automatically to a more cost-efficient storage class.\\nAmazon S3 on Outposts brings storage to installations not hosted by Amazon.\\nAmazon S3 Glacier Instant Retrieval is a low-cost storage for rarely accessed data, but which still requires rapid retrieval.\\nAmazon S3 Glacier Flexible Retrieval is also a low-cost option for long-lived data; it offers 3 retrieval speeds, ranging from minutes to hours.\\nAmazon S3 Glacier Deep Archive is the lowest cost storage for long-lived archive data that is accessed less than once per year and is retrieved asynchronously.The Amazon S3 Glacier storage classes above are distinct from Amazon Glacier, which is a separate product with its own APIs.',\n",
       "  '=== File size limits ===\\nAn object in S3 can be between 0 bytes and 5TB. If an object is larger than 5TB, it must be divided into chunks prior to uploading. When uploading, Amazon S3 allows a maximum of 5GB in a single upload operation; hence, objects larger than 5GB must be uploaded via the S3 multipart upload API.\\n\\n\\n== Uses ==',\n",
       "  '=== Notable users ===\\nPhoto hosting service SmugMug has used Amazon S3 since April 2006. They experienced a number of initial outages and slowdowns, but after one year they described it as being \"considerably more reliable than our own internal storage\" and claimed to have saved almost $1 million in storage costs.\\nNetflix uses Amazon S3 as their system of record. Netflix implemented a tool, S3mper, to address the Amazon S3 limitations of eventual consistency. S3mper stores the filesystem metadata: filenames, directory structure, and permissions in Amazon DynamoDB.\\nReddit is hosted on Amazon S3.',\n",
       "  \"Reddit is hosted on Amazon S3.\\nBitcasa, and Tahoe-LAFS-on-S3, among others, use Amazon S3 for online backup and synchronization services. In 2016, Dropbox stopped using Amazon S3 services and developed its own cloud server.\\nSwiftype's CEO has mentioned that the company uses Amazon S3.\",\n",
       "  '=== S3 API and competing services ===\\nThe broad adoption of Amazon S3 and related tooling has given rise to competing services based on the S3 API. These services use the standard programming interface but are differentiated by their underlying technologies and business models. A standard interface enables better competition from rival providers and allows economies of scale in implementation, among other benefits.\\n\\n\\n== History ==\\nAmazon Web Services introduced Amazon S3 in 2006.\\nIn November 2017 AWS added default encryption capabilities at bucket level.\\n\\n\\n== See also ==\\nAmazon Elastic Block Storage (EBS)\\nTimeline of Amazon Web Services\\n\\n\\n== References ==\\n\\n\\n=== Citations ===\\n\\n\\n=== Sources ===']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220950d8-d60c-4d9f-91d7-93b1cba42823",
   "metadata": {},
   "source": [
    "### -완전한 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad6ad0d2-f224-4d11-a159-3fe2c8017d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " According to the context, Amazon S3 offers the following storage classes:\n",
      "\n",
      "1. Amazon S3 Standard \n",
      "2. Amazon S3 Express One Zone\n",
      "3. Amazon S3 Standard-Infrequent Access (Standard-IA)  \n",
      "4. Amazon S3 One Zone-Infrequent Access (One Zone-IA)\n",
      "5. Amazon S3 Intelligent-Tiering \n",
      "6. Amazon S3 on Outposts  \n",
      "7. Amazon S3 Glacier Instant Retrieval\n",
      "8. Amazon S3 Glacier Flexible Retrieval  \n",
      "9. Amazon S3 Glacier Deep Archive\n"
     ]
    }
   ],
   "source": [
    "answer = llm(prompt.format(context=context, question=question))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a011d217-0a6c-47d0-b563-4c97699da083",
   "metadata": {},
   "source": [
    "### Topology 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7cda0357-a2bc-4c44-85f3-2b3d1e26f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Run the below Cypher Query ----\n",
    "# MATCH (s1:Service {name: 'Amazon S3'})\n",
    "# MERGE (s2:Service {name: 'Amazon EBS'})\n",
    "# MERGE (ec2:Service {name: 'Amazon EC2'})\n",
    "# MERGE (ec2)-[:hasStorageType]->(s1)\n",
    "# MERGE (ec2)-[:hasStorageType]->(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d25b85-a05e-40b7-96e1-2215f709dec0",
   "metadata": {},
   "source": [
    "<img src=\"./image/query1.png\">\n",
    "<img src=\"./image/topo1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a385293c-5c15-4120-8354-6c1e262fd896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>seqId</th>\n",
       "      <th>contextId</th>\n",
       "      <th>textEmbedding</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon EC20</td>\n",
       "      <td>[0.29492188, 0.07910156, 0.87890625, -0.193359...</td>\n",
       "      <td>Amazon Elastic Compute Cloud (EC2) is a part o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon EC21</td>\n",
       "      <td>[0.10253906, 0.33398438, 0.55859375, -0.208984...</td>\n",
       "      <td>Amazon announced a limited public beta test of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>2</td>\n",
       "      <td>Amazon EC22</td>\n",
       "      <td>[0.16796875, -0.032714844, 0.7421875, -0.27734...</td>\n",
       "      <td>a service level agreement for EC2,\\nMicrosoft ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>3</td>\n",
       "      <td>Amazon EC23</td>\n",
       "      <td>[0.024902344, -0.1328125, 0.46875, -0.28710938...</td>\n",
       "      <td>== Instance types ==\\nInitially, EC2 used Xen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>4</td>\n",
       "      <td>Amazon EC24</td>\n",
       "      <td>[-0.328125, 0.068847656, 0.21484375, -0.102050...</td>\n",
       "      <td>Compute Optimized: C5, C5n, C4\\nMemory Optimiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazon EC25</td>\n",
       "      <td>[-0.16894531, 0.047607422, 0.69921875, 0.14550...</td>\n",
       "      <td>=== Cost ===\\nAs of April 2018, Amazon charged...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>6</td>\n",
       "      <td>Amazon EC26</td>\n",
       "      <td>[-0.3046875, -0.01940918, 0.80859375, -0.11718...</td>\n",
       "      <td>=== Free tier ===\\nAs of December 2010 Amazon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>7</td>\n",
       "      <td>Amazon EC27</td>\n",
       "      <td>[-0.51171875, 0.06982422, 0.45898438, -0.15820...</td>\n",
       "      <td>=== Reserved instances ===\\nReserved instances...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>8</td>\n",
       "      <td>Amazon EC28</td>\n",
       "      <td>[-0.20898438, -0.06689453, 0.30859375, -0.3652...</td>\n",
       "      <td>In September 2016, AWS announced several enhan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>9</td>\n",
       "      <td>Amazon EC29</td>\n",
       "      <td>[-0.0026397705, 0.24902344, 0.546875, -0.22851...</td>\n",
       "      <td>=== Spot instances ===\\nCloud providers mainta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>10</td>\n",
       "      <td>Amazon EC210</td>\n",
       "      <td>[0.44921875, 0.609375, 0.057373047, -0.0378417...</td>\n",
       "      <td>=== Savings Plans ===</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>11</td>\n",
       "      <td>Amazon EC211</td>\n",
       "      <td>[0.22558594, -0.0069274902, 0.66796875, -0.324...</td>\n",
       "      <td>In November 2019, Amazon announced Savings Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>12</td>\n",
       "      <td>Amazon EC212</td>\n",
       "      <td>[0.26171875, 0.055664062, 0.7109375, -0.453125...</td>\n",
       "      <td>allow an organization to commit to EC2 and Far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>13</td>\n",
       "      <td>Amazon EC213</td>\n",
       "      <td>[0.24902344, -0.15625, 0.40625, -0.44335938, 0...</td>\n",
       "      <td>plans provide a larger discount than Compute S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>14</td>\n",
       "      <td>Amazon EC214</td>\n",
       "      <td>[0.24902344, -0.115234375, 0.78125, -0.1210937...</td>\n",
       "      <td>instances within the family in that region.AWS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>15</td>\n",
       "      <td>Amazon EC215</td>\n",
       "      <td>[0.42578125, 0.033691406, 0.69140625, -0.24121...</td>\n",
       "      <td>bill. AWS Savings Plans are purchased based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>16</td>\n",
       "      <td>Amazon EC216</td>\n",
       "      <td>[-0.07861328, 0.10839844, -0.028442383, -0.052...</td>\n",
       "      <td>to spending $5 per hour, on a Compute Savings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>17</td>\n",
       "      <td>Amazon EC217</td>\n",
       "      <td>[0.52734375, -0.3359375, 0.13964844, 0.4316406...</td>\n",
       "      <td>== Features ==\\n\\n\\n=== Operating systems ===</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>18</td>\n",
       "      <td>Amazon EC218</td>\n",
       "      <td>[0.14746094, 0.003753662, 0.61328125, -0.29101...</td>\n",
       "      <td>When it launched in August 2006, the EC2 servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>19</td>\n",
       "      <td>Amazon EC219</td>\n",
       "      <td>[0.36523438, -0.059570312, 0.53125, -0.0349121...</td>\n",
       "      <td>Linux kernel version 3.4.34\\nJava OpenJDK Runt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>20</td>\n",
       "      <td>Amazon EC220</td>\n",
       "      <td>[0.08203125, -0.24902344, 0.625, -0.28320312, ...</td>\n",
       "      <td>=== Persistent storage ===\\nAn EC2 instance ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>21</td>\n",
       "      <td>Amazon EC221</td>\n",
       "      <td>[-0.14941406, -0.056884766, 0.65625, -0.291015...</td>\n",
       "      <td>The Amazon Elastic Block Store (EBS) provides ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>22</td>\n",
       "      <td>Amazon EC222</td>\n",
       "      <td>[0.0546875, -0.40820312, 0.83203125, -0.5, -0....</td>\n",
       "      <td>EBS volumes provide persistent storage indepen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>23</td>\n",
       "      <td>Amazon EC223</td>\n",
       "      <td>[0.09765625, -0.89453125, 0.5625, -0.13574219,...</td>\n",
       "      <td>system that are backed by Amazon's disk arrays...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>24</td>\n",
       "      <td>Amazon EC224</td>\n",
       "      <td>[-0.007598877, -0.49023438, 0.54296875, -0.498...</td>\n",
       "      <td>as a hard drive. Another possible use is the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>25</td>\n",
       "      <td>Amazon EC225</td>\n",
       "      <td>[0.171875, -0.03540039, 0.6953125, -0.3671875,...</td>\n",
       "      <td>and manage storage volumes of sizes from 1GB t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>26</td>\n",
       "      <td>Amazon EC226</td>\n",
       "      <td>[0.75, -0.55078125, 0.64453125, -0.20605469, 0...</td>\n",
       "      <td>from instances while they are running, and mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>27</td>\n",
       "      <td>Amazon EC227</td>\n",
       "      <td>[0.3125, -0.359375, 0.9375, -0.53125, -0.13671...</td>\n",
       "      <td>to suitably authenticated callers (all communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>28</td>\n",
       "      <td>Amazon EC228</td>\n",
       "      <td>[-0.07421875, -0.13183594, 0.91015625, -0.6875...</td>\n",
       "      <td>stored in a different region (for example, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>29</td>\n",
       "      <td>Amazon EC229</td>\n",
       "      <td>[0.38085938, -0.40625, 0.45898438, -0.18847656...</td>\n",
       "      <td>S3-based storage is priced per gigabyte per mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>30</td>\n",
       "      <td>Amazon EC230</td>\n",
       "      <td>[-0.088378906, -0.011291504, 0.390625, -0.1328...</td>\n",
       "      <td>=== Elastic IP addresses ===\\nAmazon's elastic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>31</td>\n",
       "      <td>Amazon EC231</td>\n",
       "      <td>[0.29882812, 0.34570312, 0.94921875, -0.511718...</td>\n",
       "      <td>=== Amazon CloudWatch ===</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>32</td>\n",
       "      <td>Amazon EC232</td>\n",
       "      <td>[0.31445312, -0.25390625, 0.9375, -0.37304688,...</td>\n",
       "      <td>Amazon CloudWatch is a web service that provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>33</td>\n",
       "      <td>Amazon EC233</td>\n",
       "      <td>[0.114746094, -0.24609375, 1.125, -0.25390625,...</td>\n",
       "      <td>Since May 2011, Amazon CloudWatch accepts cust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>34</td>\n",
       "      <td>Amazon EC234</td>\n",
       "      <td>[0.20117188, -0.075683594, 0.45507812, -0.1855...</td>\n",
       "      <td>=== Automated scaling ===\\n\\nAmazon's auto-sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>35</td>\n",
       "      <td>Amazon EC235</td>\n",
       "      <td>[-0.4296875, 0.43554688, 0.8046875, 0.00799560...</td>\n",
       "      <td>On Demand EC2 instances are priced per hour. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>36</td>\n",
       "      <td>Amazon EC236</td>\n",
       "      <td>[-0.15234375, 0.66015625, 0.8203125, -0.143554...</td>\n",
       "      <td>Amazon EC2 price varies from $2.5 per month fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>37</td>\n",
       "      <td>Amazon EC237</td>\n",
       "      <td>[0.17089844, -0.24023438, 0.39453125, -0.38867...</td>\n",
       "      <td>== Reliability ==\\nTo make EC2 more fault-tole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>38</td>\n",
       "      <td>Amazon EC238</td>\n",
       "      <td>[0.22070312, 0.15527344, 0.38476562, -0.373046...</td>\n",
       "      <td>== Issues ==\\nIn early July 2008, the anti-spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>39</td>\n",
       "      <td>Amazon EC239</td>\n",
       "      <td>[0.05493164, 0.22265625, 0.3984375, -0.3320312...</td>\n",
       "      <td>Shortly before 5 am ET on April 21, 2011, an o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>40</td>\n",
       "      <td>Amazon EC240</td>\n",
       "      <td>[0.029785156, -0.13671875, 0.17382812, -0.3066...</td>\n",
       "      <td>On Sunday August 6, 2011, Amazon suffered a po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>41</td>\n",
       "      <td>Amazon EC241</td>\n",
       "      <td>[0.14160156, -0.11279297, -0.18457031, -0.2578...</td>\n",
       "      <td>Another Northern Virginia data center outage o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Amazon EC2</td>\n",
       "      <td>42</td>\n",
       "      <td>Amazon EC242</td>\n",
       "      <td>[1.9453125, 0.26367188, 0.6171875, -0.44921875...</td>\n",
       "      <td>== See also ==\\n\\n\\n== Notes ==\\n\\n\\n== Refere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  seqId     contextId  \\\n",
       "0   Amazon EC2      0   Amazon EC20   \n",
       "1   Amazon EC2      1   Amazon EC21   \n",
       "2   Amazon EC2      2   Amazon EC22   \n",
       "3   Amazon EC2      3   Amazon EC23   \n",
       "4   Amazon EC2      4   Amazon EC24   \n",
       "5   Amazon EC2      5   Amazon EC25   \n",
       "6   Amazon EC2      6   Amazon EC26   \n",
       "7   Amazon EC2      7   Amazon EC27   \n",
       "8   Amazon EC2      8   Amazon EC28   \n",
       "9   Amazon EC2      9   Amazon EC29   \n",
       "10  Amazon EC2     10  Amazon EC210   \n",
       "11  Amazon EC2     11  Amazon EC211   \n",
       "12  Amazon EC2     12  Amazon EC212   \n",
       "13  Amazon EC2     13  Amazon EC213   \n",
       "14  Amazon EC2     14  Amazon EC214   \n",
       "15  Amazon EC2     15  Amazon EC215   \n",
       "16  Amazon EC2     16  Amazon EC216   \n",
       "17  Amazon EC2     17  Amazon EC217   \n",
       "18  Amazon EC2     18  Amazon EC218   \n",
       "19  Amazon EC2     19  Amazon EC219   \n",
       "20  Amazon EC2     20  Amazon EC220   \n",
       "21  Amazon EC2     21  Amazon EC221   \n",
       "22  Amazon EC2     22  Amazon EC222   \n",
       "23  Amazon EC2     23  Amazon EC223   \n",
       "24  Amazon EC2     24  Amazon EC224   \n",
       "25  Amazon EC2     25  Amazon EC225   \n",
       "26  Amazon EC2     26  Amazon EC226   \n",
       "27  Amazon EC2     27  Amazon EC227   \n",
       "28  Amazon EC2     28  Amazon EC228   \n",
       "29  Amazon EC2     29  Amazon EC229   \n",
       "30  Amazon EC2     30  Amazon EC230   \n",
       "31  Amazon EC2     31  Amazon EC231   \n",
       "32  Amazon EC2     32  Amazon EC232   \n",
       "33  Amazon EC2     33  Amazon EC233   \n",
       "34  Amazon EC2     34  Amazon EC234   \n",
       "35  Amazon EC2     35  Amazon EC235   \n",
       "36  Amazon EC2     36  Amazon EC236   \n",
       "37  Amazon EC2     37  Amazon EC237   \n",
       "38  Amazon EC2     38  Amazon EC238   \n",
       "39  Amazon EC2     39  Amazon EC239   \n",
       "40  Amazon EC2     40  Amazon EC240   \n",
       "41  Amazon EC2     41  Amazon EC241   \n",
       "42  Amazon EC2     42  Amazon EC242   \n",
       "\n",
       "                                        textEmbedding  \\\n",
       "0   [0.29492188, 0.07910156, 0.87890625, -0.193359...   \n",
       "1   [0.10253906, 0.33398438, 0.55859375, -0.208984...   \n",
       "2   [0.16796875, -0.032714844, 0.7421875, -0.27734...   \n",
       "3   [0.024902344, -0.1328125, 0.46875, -0.28710938...   \n",
       "4   [-0.328125, 0.068847656, 0.21484375, -0.102050...   \n",
       "5   [-0.16894531, 0.047607422, 0.69921875, 0.14550...   \n",
       "6   [-0.3046875, -0.01940918, 0.80859375, -0.11718...   \n",
       "7   [-0.51171875, 0.06982422, 0.45898438, -0.15820...   \n",
       "8   [-0.20898438, -0.06689453, 0.30859375, -0.3652...   \n",
       "9   [-0.0026397705, 0.24902344, 0.546875, -0.22851...   \n",
       "10  [0.44921875, 0.609375, 0.057373047, -0.0378417...   \n",
       "11  [0.22558594, -0.0069274902, 0.66796875, -0.324...   \n",
       "12  [0.26171875, 0.055664062, 0.7109375, -0.453125...   \n",
       "13  [0.24902344, -0.15625, 0.40625, -0.44335938, 0...   \n",
       "14  [0.24902344, -0.115234375, 0.78125, -0.1210937...   \n",
       "15  [0.42578125, 0.033691406, 0.69140625, -0.24121...   \n",
       "16  [-0.07861328, 0.10839844, -0.028442383, -0.052...   \n",
       "17  [0.52734375, -0.3359375, 0.13964844, 0.4316406...   \n",
       "18  [0.14746094, 0.003753662, 0.61328125, -0.29101...   \n",
       "19  [0.36523438, -0.059570312, 0.53125, -0.0349121...   \n",
       "20  [0.08203125, -0.24902344, 0.625, -0.28320312, ...   \n",
       "21  [-0.14941406, -0.056884766, 0.65625, -0.291015...   \n",
       "22  [0.0546875, -0.40820312, 0.83203125, -0.5, -0....   \n",
       "23  [0.09765625, -0.89453125, 0.5625, -0.13574219,...   \n",
       "24  [-0.007598877, -0.49023438, 0.54296875, -0.498...   \n",
       "25  [0.171875, -0.03540039, 0.6953125, -0.3671875,...   \n",
       "26  [0.75, -0.55078125, 0.64453125, -0.20605469, 0...   \n",
       "27  [0.3125, -0.359375, 0.9375, -0.53125, -0.13671...   \n",
       "28  [-0.07421875, -0.13183594, 0.91015625, -0.6875...   \n",
       "29  [0.38085938, -0.40625, 0.45898438, -0.18847656...   \n",
       "30  [-0.088378906, -0.011291504, 0.390625, -0.1328...   \n",
       "31  [0.29882812, 0.34570312, 0.94921875, -0.511718...   \n",
       "32  [0.31445312, -0.25390625, 0.9375, -0.37304688,...   \n",
       "33  [0.114746094, -0.24609375, 1.125, -0.25390625,...   \n",
       "34  [0.20117188, -0.075683594, 0.45507812, -0.1855...   \n",
       "35  [-0.4296875, 0.43554688, 0.8046875, 0.00799560...   \n",
       "36  [-0.15234375, 0.66015625, 0.8203125, -0.143554...   \n",
       "37  [0.17089844, -0.24023438, 0.39453125, -0.38867...   \n",
       "38  [0.22070312, 0.15527344, 0.38476562, -0.373046...   \n",
       "39  [0.05493164, 0.22265625, 0.3984375, -0.3320312...   \n",
       "40  [0.029785156, -0.13671875, 0.17382812, -0.3066...   \n",
       "41  [0.14160156, -0.11279297, -0.18457031, -0.2578...   \n",
       "42  [1.9453125, 0.26367188, 0.6171875, -0.44921875...   \n",
       "\n",
       "                                                 text  \n",
       "0   Amazon Elastic Compute Cloud (EC2) is a part o...  \n",
       "1   Amazon announced a limited public beta test of...  \n",
       "2   a service level agreement for EC2,\\nMicrosoft ...  \n",
       "3   == Instance types ==\\nInitially, EC2 used Xen ...  \n",
       "4   Compute Optimized: C5, C5n, C4\\nMemory Optimiz...  \n",
       "5   === Cost ===\\nAs of April 2018, Amazon charged...  \n",
       "6   === Free tier ===\\nAs of December 2010 Amazon ...  \n",
       "7   === Reserved instances ===\\nReserved instances...  \n",
       "8   In September 2016, AWS announced several enhan...  \n",
       "9   === Spot instances ===\\nCloud providers mainta...  \n",
       "10                              === Savings Plans ===  \n",
       "11  In November 2019, Amazon announced Savings Pla...  \n",
       "12  allow an organization to commit to EC2 and Far...  \n",
       "13  plans provide a larger discount than Compute S...  \n",
       "14  instances within the family in that region.AWS...  \n",
       "15  bill. AWS Savings Plans are purchased based on...  \n",
       "16  to spending $5 per hour, on a Compute Savings ...  \n",
       "17      == Features ==\\n\\n\\n=== Operating systems ===  \n",
       "18  When it launched in August 2006, the EC2 servi...  \n",
       "19  Linux kernel version 3.4.34\\nJava OpenJDK Runt...  \n",
       "20  === Persistent storage ===\\nAn EC2 instance ma...  \n",
       "21  The Amazon Elastic Block Store (EBS) provides ...  \n",
       "22  EBS volumes provide persistent storage indepen...  \n",
       "23  system that are backed by Amazon's disk arrays...  \n",
       "24  as a hard drive. Another possible use is the c...  \n",
       "25  and manage storage volumes of sizes from 1GB t...  \n",
       "26  from instances while they are running, and mov...  \n",
       "27  to suitably authenticated callers (all communi...  \n",
       "28  stored in a different region (for example, dat...  \n",
       "29  S3-based storage is priced per gigabyte per mo...  \n",
       "30  === Elastic IP addresses ===\\nAmazon's elastic...  \n",
       "31                          === Amazon CloudWatch ===  \n",
       "32  Amazon CloudWatch is a web service that provid...  \n",
       "33  Since May 2011, Amazon CloudWatch accepts cust...  \n",
       "34  === Automated scaling ===\\n\\nAmazon's auto-sca...  \n",
       "35  On Demand EC2 instances are priced per hour. A...  \n",
       "36  Amazon EC2 price varies from $2.5 per month fo...  \n",
       "37  == Reliability ==\\nTo make EC2 more fault-tole...  \n",
       "38  == Issues ==\\nIn early July 2008, the anti-spa...  \n",
       "39  Shortly before 5 am ET on April 21, 2011, an o...  \n",
       "40  On Sunday August 6, 2011, Amazon suffered a po...  \n",
       "41  Another Northern Virginia data center outage o...  \n",
       "42  == See also ==\\n\\n\\n== Notes ==\\n\\n\\n== Refere...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Amazon EC2'\n",
    "vector = create_text_embedding_entries(query, chunk_size, chunk_overlap)\n",
    "pd.DataFrame(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14882e0c-8292-4808-9e82-f9db4de073d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_embeddings(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ed98a86-ab34-4474-9c99-e59a554f4e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>seqId</th>\n",
       "      <th>contextId</th>\n",
       "      <th>textEmbedding</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon EBS</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon EBS0</td>\n",
       "      <td>[0.09326172, -0.18554688, 0.9140625, -0.324218...</td>\n",
       "      <td>Amazon Elastic Block Store (EBS) provides raw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon EBS</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon EBS1</td>\n",
       "      <td>[0.25585938, -0.20117188, 0.703125, -0.4433593...</td>\n",
       "      <td>== Use case ==\\nIn a typical use case, using E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon EBS</td>\n",
       "      <td>2</td>\n",
       "      <td>Amazon EBS2</td>\n",
       "      <td>[0.28515625, -0.09863281, 0.63671875, -0.74218...</td>\n",
       "      <td>== Volume types ==\\nThe following table shows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon EBS</td>\n",
       "      <td>3</td>\n",
       "      <td>Amazon EBS3</td>\n",
       "      <td>[0.29882812, -0.13964844, 0.81640625, -0.38281...</td>\n",
       "      <td>== Features ==\\nAmazon EBS provides several fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon EBS</td>\n",
       "      <td>4</td>\n",
       "      <td>Amazon EBS4</td>\n",
       "      <td>[0.87109375, -0.39453125, 0.99609375, -0.20800...</td>\n",
       "      <td>== See also ==\\nAmazon Elastic File System (EF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  seqId    contextId  \\\n",
       "0  Amazon EBS      0  Amazon EBS0   \n",
       "1  Amazon EBS      1  Amazon EBS1   \n",
       "2  Amazon EBS      2  Amazon EBS2   \n",
       "3  Amazon EBS      3  Amazon EBS3   \n",
       "4  Amazon EBS      4  Amazon EBS4   \n",
       "\n",
       "                                       textEmbedding  \\\n",
       "0  [0.09326172, -0.18554688, 0.9140625, -0.324218...   \n",
       "1  [0.25585938, -0.20117188, 0.703125, -0.4433593...   \n",
       "2  [0.28515625, -0.09863281, 0.63671875, -0.74218...   \n",
       "3  [0.29882812, -0.13964844, 0.81640625, -0.38281...   \n",
       "4  [0.87109375, -0.39453125, 0.99609375, -0.20800...   \n",
       "\n",
       "                                                text  \n",
       "0  Amazon Elastic Block Store (EBS) provides raw ...  \n",
       "1  == Use case ==\\nIn a typical use case, using E...  \n",
       "2  == Volume types ==\\nThe following table shows ...  \n",
       "3  == Features ==\\nAmazon EBS provides several fe...  \n",
       "4  == See also ==\\nAmazon Elastic File System (EF...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Amazon EBS'\n",
    "ebs_vector = create_text_embedding_entries(query, chunk_size, chunk_overlap)\n",
    "pd.DataFrame(ebs_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "144b7e6c-0b82-4771-bcd2-bf14fe965476",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_embeddings(ebs_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946fd10-0362-4e97-bf08-2e41ad56a108",
   "metadata": {},
   "source": [
    "<img src=\"./image/topo2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e46ea-3e98-48f9-b0b1-aec61778c75f",
   "metadata": {},
   "source": [
    "### -Vector Similarity 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61ab7ba9-55bd-4ca6-b122-9fb7e62fdd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search = \"\"\"\n",
    "WITH $embedding AS e\n",
    "CALL db.index.vector.queryNodes('vector', $k, e) yield node, score\n",
    "MATCH (s:Service)-[:CHUNKED]->(node)\n",
    "WITH s\n",
    "MATCH (s)-[:CHUNKED]->(docs:Chunk)\n",
    "WITH s, docs\n",
    "ORDER BY docs.seqid ASC\n",
    "RETURN s AS service, COLLECT(docs.text) AS result\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1240aa84-d475-47c9-9051-f3d7aa6f0ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "Tell me about the different storage types available for Amazon EC2. \n",
    "I need detailed information on the characteristics and use cases for each storage type. \n",
    "Additionally, I want to know which storage type is best suited for perfgormance.\n",
    "\"\"\"\n",
    "embedding = bedrock_embeddings.embed_query(question)\n",
    "context = graph_instance.query(\n",
    "    vector_search, {'embedding': embedding, 'k': 1})\n",
    "context = [el['result'] for el in context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f8539d03-da65-4e96-ae49-f4a26e229cf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Amazon Elastic Compute Cloud (EC2) is a part of Amazon.com\\'s cloud-computing platform, Amazon Web Services (AWS), that allows users to rent virtual computers on which to run their own computer applications. EC2 encourages scalable deployment of applications by providing a web service through which a user can boot an Amazon Machine Image (AMI) to configure a virtual machine, which Amazon calls an \"instance\", containing any software desired. A user can create, launch, and terminate server-instances as needed, paying by the second for active servers – hence the term \"elastic\". EC2 provides users with control over the geographical location of instances that allows for latency optimization and high levels of redundancy. In November 2010, Amazon switched its own retail website platform to EC2 and AWS.\\n\\n\\n== History ==',\n",
       "  'Amazon announced a limited public beta test of EC2 on August 25, 2006, offering access on a first-come, first-served basis.\\nAmazon added two new instance types (Large and Extra-Large) on October 16, 2007. On May 29, 2008, two more types were added, High-CPU Medium and High-CPU Extra Large. There were twelve types of instances available.Amazon added three new features on March 27, 2008, static IP addresses, availability zones, and user selectable kernels. On August 20, 2008, Amazon added Elastic Block Store (EBS)\\nThis provides persistent storage, a feature that had been lacking since the service was introduced.\\nAmazon EC2 went into full production when it dropped the beta label on October 23, 2008. On the same day, Amazon announced the following features:\\na service level agreement for EC2,',\n",
       "  'a service level agreement for EC2,\\nMicrosoft Windows in beta form on EC2,\\nMicrosoft SQL Server in beta form on EC2,\\nplans for an AWS management console, and\\nplans for load balancing, autoscaling, and cloud monitoring services.These features were subsequently added on May 18, 2009.Amazon EC2 was developed mostly by a team in Cape Town, South Africa led by Chris Pinkham. Pinkham provided the initial architecture guidance for EC2 and then built the team and led the development of the project along with Willem van Biljon.',\n",
       "  '== Instance types ==\\nInitially, EC2 used Xen virtualization exclusively. However, on November 6, 2017, Amazon announced the new C5 family of instances that were based on a custom architecture around the KVM hypervisor, called Nitro. Each virtual machine, called an \"instance\", functions as a virtual private server. Amazon sizes instances based on \"Elastic Compute Units\". The performance of otherwise identical virtual machines may vary. On November 28, 2017, AWS announced a bare-metal instance type offering marking a remarkable departure from exclusively offering virtualized instance types.As of January 2019, the following instance types were offered:\\nGeneral Purpose: A1, T3, T2, M5, M5a, M4, T3a\\nCompute Optimized: C5, C5n, C4',\n",
       "  'Compute Optimized: C5, C5n, C4\\nMemory Optimized: R5, R5a, R4, X1e, X1, High Memory, z1d\\nAccelerated Computing: P3, P2, G3, F1\\nStorage Optimized: H1, I3, D2As of April 2018, the following payment methods by instance were offered:\\nOn-demand: pay by the hour without commitment.\\nReserved: rent instances with one-time payment receiving discounts on the hourly charge.\\nSpot: bid-based service: runs the jobs only if the spot price is below the bid specified by bidder. The spot price is claimed to be supply-demand based, however a 2011 study concluded that the price was generally not set to clear the market, but was dominated by an undisclosed reserve price.',\n",
       "  '=== Cost ===\\nAs of April 2018, Amazon charged about $0.0058 per hour ($4.176 per month) for the smallest \"Nano Instance\" (t2.nano) virtual machine running Linux or Windows. Storage-optimized instances cost as much as $4.992 per hour (i3.16xlarge). \"Reserved\" instances can go as low as $2.50 per month for a three-year prepaid plan. The data transfer charge ranges from free to $0.12 per gigabyte, depending on the direction and monthly volume (inbound data transfer is free on all AWS services).\\nEC2 costs can be analyzed using the Amazon Cost and Usage Report. There are many different cost categories for EC2 including: hourly Instance Charges, Data Transfer, EBS Volumes, EBS Volume Snapshots, and Nat Gateway.',\n",
       "  '=== Free tier ===\\nAs of December 2010 Amazon offered a bundle of free resource credits to new account holders. The credits are designed to run a \"micro\" sized server, storage (EBS), and bandwidth for one year. Unused credits cannot be carried over from one month to the next.',\n",
       "  '=== Reserved instances ===\\nReserved instances enable EC2 or RDS service users to reserve an instance for one or three years. The corresponding hourly rate charged by Amazon to operate the instance is 35 to 75% lower than the rate charged for on-demand instances.\\nReserved instances can be purchased with three different payment options: All Upfront, Partial Upfront and No Upfront. The different purchase options allow for different structuring of payment models, with a larger discount given to customers that pay their reservation upfront.Reserved Instances are purchased based on a resource commitment. These reservations are made based on an instance type and a count of that instance type.  For example, you could reserve 100, i3.large instances, for a 3-year term.',\n",
       "  'In September 2016, AWS announced several enhancements to Reserved instances, introducing a new feature called scope and a new reservation type called a Convertible. In October 2017, AWS announced the allowance to subdivide the instances purchased for more flexibility',\n",
       "  '=== Spot instances ===\\nCloud providers maintain large amounts of excess capacity they have to sell or risk incurring losses.\\nAmazon EC2 Spot instances are spare compute capacity in the AWS cloud available at up to 90% discount compared to On-Demand prices. As a trade-off, AWS offers no SLA on these instances and customers take the risk that it can be interrupted with only two minutes of notification when Amazon needs the capacity back. Researchers from the Israeli Institute of Technology found that \"they (Spot instances) are typically generated at random from within a tight price interval via a dynamic hidden reserve price\". Some companies, like Spotinst, are using machine learning to predict spot interruptions up to 15 minutes in advance.',\n",
       "  '=== Savings Plans ===',\n",
       "  'In November 2019, Amazon announced Savings Plans. Savings Plans are an alternative to Reserved Instances that come in two different plan types: Compute Savings Plans and EC2 Instances Savings Plans. Compute Savings Plans allow an organization to commit to',\n",
       "  'allow an organization to commit to EC2 and Fargate usage with the freedom to change region, family, size, availability zone, OS and tenancy inside the lifespan of the commitment. EC2 Instance Savings plans provide a larger discount than',\n",
       "  'plans provide a larger discount than Compute Savings Plans but are less flexible meaning a user must commit to individual instance families within a region to take advantage, but with the freedom to change instances within the family in that',\n",
       "  'instances within the family in that region.AWS uses the Cost Explorer to automatically calculate recommendations for the commitments you should make how that commitment will look like as a monthly charge on your AWS bill. AWS Savings Plans are',\n",
       "  'bill. AWS Savings Plans are purchased based on hourly spend commitment. This hourly commitment is made using the discounted pricing of the savings plan you are purchasing. For example, you could commit to spending $5 per hour, on',\n",
       "  'to spending $5 per hour, on a Compute Savings Plan, for a 3-year term.',\n",
       "  '== Features ==\\n\\n\\n=== Operating systems ===',\n",
       "  \"When it launched in August 2006, the EC2 service offered Linux and later Sun Microsystems' OpenSolaris and Solaris Express Community Edition. In October 2008, EC2 added the Windows Server 2003 and Windows Server 2008 operating systems to the list of available operating systems.\\nIn March 2011, NetBSD AMIs became available. In November 2012, Windows Server 2012 support was added.Since 2006, Colin Percival, a FreeBSD developer and Security Officer, solicited Amazon to add FreeBSD. In November 2012, Amazon officially supported running FreeBSD in EC2. The FreeBSD/EC2 platform is maintained by Percival who also developed the secure deduplicating Amazon S3-cloud based backup service Tarsnap.Amazon has their own Linux distribution based on Fedora and Red Hat Enterprise Linux as a low cost offering known as the Amazon Linux AMI. Version 2013.03 included:\",\n",
       "  'Linux kernel version 3.4.34\\nJava OpenJDK Runtime Environment (IcedTea6 1.11.4)\\nGNU Compiler Collection gcc.x86_64 4.4.6-3.45.amzn1On November 30, 2020, Amazon announced that it would be adding macOS to the EC2 service. Initial support was announced for macOS Mojave and macOS Catalina running on Mac Mini.',\n",
       "  '=== Persistent storage ===\\nAn EC2 instance may be launched with a choice of two types of storage for its boot disk or \"root device.\" The first option is a local \"instance-store\" disk as a root device (originally the only choice). The second option is to use an EBS volume as a root device. Instance-store volumes are temporary storage, which survive rebooting an EC2 instance, but when the instance is stopped or terminated (e.g., by an API call, or due to a failure), this store is lost.',\n",
       "  'The Amazon Elastic Block Store (EBS) provides raw block devices that can be attached to Amazon EC2 instances. These block devices can then be used like any raw block device. In a typical use case, this would include formatting the device with a filesystem and mounting it. In addition, EBS supports a number of advanced storage features, including snapshotting and cloning. EBS volumes can be up to 16TB in size. EBS volumes are built on replicated storage, so that the failure of a single component will not cause data loss.\\nEBS was introduced to the general public by Amazon in August 2008.',\n",
       "  \"EBS volumes provide persistent storage independent of the lifetime of the EC2 instance, and act much like hard drives on a real server. More accurately, they appear as block devices to the operating system that are backed by Amazon's\",\n",
       "  \"system that are backed by Amazon's disk arrays. The OS is free to use the device however it wants. In the most common case, a file system is loaded and the volume acts as a hard drive. Another possible\",\n",
       "  'as a hard drive. Another possible use is the creation of RAID arrays by combining two or more EBS volumes. RAID allows increases of speed and/or reliability of EBS. Users can set up and manage storage volumes of sizes',\n",
       "  'and manage storage volumes of sizes from 1GB to 16TB. The volumes support snapshots, which can be taken from a GUI tool or the API. EBS volumes can be attached or detached from instances while they are running,',\n",
       "  'from instances while they are running, and moved from one instance to another.Simple Storage Service (S3) is a storage system in which data is accessible to EC2 instances, or directly over the network to suitably authenticated callers (all',\n",
       "  'to suitably authenticated callers (all communication is over HTTP). Amazon does not charge for the bandwidth for communications between EC2 instances and S3 storage \"in the same region.\" Accessing S3 data stored in a different region (for',\n",
       "  \"stored in a different region (for example, data stored in Europe from a US East Coast EC2 instance) will be billed at Amazon's normal rates.\",\n",
       "  'S3-based storage is priced per gigabyte per month. Applications access S3 through an API. For example, Apache Hadoop supports a special s3: filesystem to support reading from and writing to S3 storage during a MapReduce job. There are also S3 filesystems for Linux, which mount a remote S3 filestore on an EC2 image, as if it were local storage. As S3 is not a full POSIX filesystem, things may not behave the same as on a local disk (e.g., no locking support).',\n",
       "  \"=== Elastic IP addresses ===\\nAmazon's elastic IP address feature is similar to static IP address in traditional data centers, with one key difference. A user can programmatically map an elastic IP address to any virtual machine instance without a network administrator's help and without having to wait for DNS to propagate the binding. In this sense an Elastic IP Address belongs to the account and not to a virtual machine instance. It exists until it is explicitly removed, and remains associated with the account even while it is associated with no instance.\",\n",
       "  '=== Amazon CloudWatch ===',\n",
       "  \"Amazon CloudWatch is a web service that provides real-time monitoring to Amazon's EC2 customers on their resource utilization such as CPU, disk, network and replica lag for RDS Database replicas. CloudWatch does not provide any memory, disk space, or load average metrics without running additional software on the instance. Since December 2017 Amazon provides a CloudWatch Agent for Windows and Linux operating systems included disk and previously not available memory information, previously Amazon provided example scripts for Linux instances to collect OS information. The data is aggregated and provided through AWS management console. It can also be accessed through command line tools and Web APIs, if the customer desires to monitor their EC2 resources through their enterprise monitoring software. Amazon provides an API which allows clients to operate on CloudWatch alarms.The metrics collected by Amazon CloudWatch enables the auto-scaling feature to dynamically add or remove EC2 instances. The customers are charged by the number of monitoring instances.\",\n",
       "  'Since May 2011, Amazon CloudWatch accepts custom metrics that can be submitted programmatically via Web Services API and then monitored the same way as all other internal metrics, including setting up the alarms for them, and since July 2014 Cloudwatch Logs service is also available.Basic Amazon CloudWatch is included in Amazon Free Tier service.',\n",
       "  \"=== Automated scaling ===\\n\\nAmazon's auto-scaling feature of EC2 allows it to automatically adapt computing capacity to site traffic. The schedule-based (e.g. time-of-the-day) and rule-based (e.g. CPU utilization thresholds) auto scaling mechanisms are easy to use and efficient for simple applications. However, one potential problem is that VMs may take up to several minutes to be ready to use, which are not suitable for time critical applications. The VM startup time is dependent on image size, VM type, data center locations, etc. The convenience of using EC2 enables you to dynamically increase capacity in accordance with demand and access resources rapidly.\\n\\n\\n== Pricing ==\\nNOTE: the examples, figures and comparison charts in this section are from 2018 in the best case; please bear this in mind, as the situation has changed a lot from then.\",\n",
       "  'On Demand EC2 instances are priced per hour. An example of this pricing would be $0.096 per hour for a Linux, m5.large, EC2 instance in the us-east-1 region. Pricing will vary based on the instance type, region, and operating system of the instance. Public on-demand pricing for EC2 can be found on the AWS website.\\nThe other pricing models for EC2 have different pricing models.\\nSpot instances also have a cost per instance hour, but the cost will change on a regular basis based on the supply of EC2 spot capacity. \\nReserved Instances and Compute Savings plans are priced per hour. Each of these reservation tools has its own price per hour based on the payment option, term and reservation product being used. These prices are locked in for either a 1-year or 3-year term.',\n",
       "  'Amazon EC2 price varies from $2.5 per month for \"nano\" instance with 1 vCPU and 0.5 GB RAM on board to \"xlarge\" type of instances with 32 vCPU and 488 GB RAM billed up to $3997.19 per month.\\nThe charts above show how Amazon EC2 pricing is compared to similar Cloud Computing services: Microsoft Azure, Google Cloud Platform, Kamatera, and Vultr.',\n",
       "  '== Reliability ==\\nTo make EC2 more fault-tolerant, Amazon engineered Availability Zones that are designed to be insulated from failures in other availability zones. Availability zones do not share the same infrastructure. Applications running in more than one availability zone can achieve higher availability.EC2 provides users with control over the geographical location of instances that allows for latency optimization and high levels of redundancy. For example, to minimize downtime, a user can set up server instances in multiple zones that are insulated from each other for most causes of failure such that one backs up the other.\\nHigher-availability database services, like Amazon Relational Database Service run separately from EC2 instances.',\n",
       "  '== Issues ==\\nIn early July 2008, the anti-spam organizations Outblaze and Spamhaus.org began blocking Amazon\\'s EC2 address pool due to problems with the distribution of spam and malware.On December 1, 2010, Amazon pulled its service to WikiLeaks after coming under political pressure in the US. Assange said that WikiLeaks chose Amazon knowing it would probably be kicked off the service \"in order to separate rhetoric from reality\". The Internet group Anonymous attempted to attack EC2 in revenge; however, Amazon was not affected by the attack.Amazon\\'s websites were temporarily offline on December 12, 2010, although it was initially unclear if this was due to attacks or a hardware failure. An Amazon official later stated that it was due to a hardware failure.',\n",
       "  'Shortly before 5 am ET on April 21, 2011, an outage started at EC2\\'s Northern Virginia data center that brought down several websites, including Foursquare, Springpad, Reddit, Quora, and Hootsuite. Specifically, attempts to use Amazon\\'s elastic-disk and database services hung, failed, or were slow. Service was restored to some parts of the data center (three of four \"availability zones\" in Amazon\\'s terms) by late afternoon Eastern time that day; problems for at least some customers were continuing as of April 25. 0.07% of EBS volumes in one zone have also been lost; EBS failures were a part of normal operation even before this outage and were a risk documented by Amazon, though the number of failures and the number of simultaneous failures may find some EC2 users unprepared.',\n",
       "  \"On Sunday August 6, 2011, Amazon suffered a power outage in one of their Ireland availability zones. Lightning was originally blamed for the outage; however, on August 11, Irish energy supplier ESB Networks dismissed this as a cause, but at time of writing, could not confirm what the cause of the problem was. The power outage raised multiple questions regarding Amazon's EBS infrastructure, which caused several bugs in their software to be exposed. The bugs resulted in some customers' data being deleted when recovering EBS volumes in a mid-write operation during the crash.August 8, 2011, saw another network connectivity outage of Amazon's Northern Virginia data center, knocking out the likes of Reddit, Quora, Netflix and FourSquare. The outage lasted around 25 minutes.\",\n",
       "  'Another Northern Virginia data center outage occurred on October 22, 2012, from approximately 10 am to 4 pm PT. Edmodo, Airbnb, Flipboard, Reddit, and other customers were affected. Anonymous claimed responsibility, but Amazon denied this assertion.',\n",
       "  '== See also ==\\n\\n\\n== Notes ==\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nOfficial website']]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d55375a-8357-4cd3-9ec9-4f6b97b6228f",
   "metadata": {},
   "source": [
    "### -Context 기반 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "50d70989-efd7-47a4-abc7-8cd8605a03a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the context provided, here is the detailed information on the different storage types available for Amazon EC2:\n",
      "\n",
      "The two main storage options for EC2 instances are:\n",
      "\n",
      "1. Instance-store volumes:\n",
      "- These are temporary storage volumes that persist only during the lifetime of the EC2 instance. \n",
      "- When the EC2 instance is stopped or terminated, the data on instance-store volumes is lost.\n",
      "- Use cases: Good for temporary data like buffers, caches, scratch data etc. Not suitable for persistent data.\n",
      "\n",
      "2. Elastic Block Store (EBS) Volumes:  \n",
      "- EBS provides persistent block-level storage volumes that can be attached to EC2 instances. \n",
      "- EBS volumes persist independently from the EC2 instance, and act like regular hard drives.\n",
      "- Can be up to 16TB in size.\n",
      "- Data on EBS volumes persists when EC2 instance is stopped/terminated.\n",
      "- Use cases: Great for persistent storage of data like databases, application data etc.\n",
      "\n",
      "Some key characteristics of EBS:\n",
      "- Volumes can be detached from one EC2 instance and attached to another\n",
      "- Support snapshots and clones for backup/duplication\n",
      "- Built on replicated storage for high availability\n",
      "- Can be configured in RAID arrays for improved performance\n",
      "\n",
      "For high performance requirements, EBS volumes provide better performance over instance-stores. EBS volumes can be provisioned as Provisioned IOPS (SSD) volumes, which provide high IOPS for latency-sensitive workloads. \n",
      "\n",
      "So in summary, Elastic Block Store (EBS) provides persistent and high performance storage options for EC2 instances.\n"
     ]
    }
   ],
   "source": [
    "vector_answer = llm(prompt.format(context=context, question=question))\n",
    "print(vector_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b6c05-6261-4f4b-90d0-d01cb58456e6",
   "metadata": {},
   "source": [
    "### -Graph QAChain 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5dc40e13-5506-42b0-8e64-b134d972d432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Node properties are the following:\n",
      "        [{'labels': 'Chunk', 'properties': [{'property': 'seqid', 'type': 'INTEGER'}, {'property': 'embedding', 'type': 'LIST'}, {'property': 'text', 'type': 'STRING'}, {'property': 'chunkid', 'type': 'STRING'}]}, {'labels': 'Service', 'properties': [{'property': 'name', 'type': 'STRING'}]}]\n",
      "        Relationship properties are the following:\n",
      "        []\n",
      "        The relationships are the following:\n",
      "        ['(:Service)-[:CHUNKED]->(:Chunk)', '(:Service)-[:hasStorageType]->(:Service)']\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "graph_instance = Neo4jGraph(url=uri, username=username, password=password)\n",
    "print(graph_instance.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1ea2ce6d-d2b0-45c1-b9b7-ee50fa325392",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "\n",
    "You are an excellent Assistant for generating Cypher Query Language for graph searches. \n",
    "You will be exploring a graph that represents the connections between AWS services.\n",
    "\n",
    "<instruction>\n",
    "Guidance for answers below\n",
    "Each Service has relationships with other Services.\n",
    " - (s1:Service)-[:]->(s2:Service)\n",
    "Each Service node is connected to Chunks containing detailed information about the service:\n",
    " - (s1:Service)-[:CHUNKED]->(c:Chunk)\n",
    "Each Chunk has detailed information about the service in its text.\n",
    " - (c:Chunk {{c.text}})\n",
    " - RETURN c.text\n",
    "</instruction>\n",
    "\n",
    "<example>\n",
    "Here are a few examples of generated Cypher statements for particular questions:\n",
    "# Question :\n",
    "Explain storage types does Amazon EC2 have.\n",
    "# Generated Cypher :\n",
    "MATCH (ec2:Service {{name:\"Amazon EC2\"}})-[:hasStorageType]->(s:Service)\n",
    "WITH s\n",
    "MATCH (s:Service)-[:CHUNKED]->(c:Chunk)\n",
    "RETURN COLLECT(DISTINCT c.text) AS Text\n",
    "\n",
    "# Question :\n",
    "Explain the cost of each storage type of Amazon EC2.\n",
    "# Generated Cypher :\n",
    "MATCH (ec2:Service {{name:\"Amazon EC2\"}})-[:hasStorageType]->(s:Service)\n",
    "WITH s\n",
    "MATCH (s:Service)-[:CHUNKED]->(c:Chunk)\n",
    "WHERE c.text CONTAINS \"cost\"\n",
    "RETURN COLLECT(DISTINCT c.text) AS Text\n",
    "</example>\n",
    "\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "<schema>\n",
    "{schema}\n",
    "</schema>\n",
    "\n",
    "The question is: \n",
    "{question} \n",
    "\"\"\"\n",
    "\n",
    "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
    "    input_variables=['schema', 'question'], validate_template=True, template=CYPHER_GENERATION_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "314b3c4e-82df-4b44-9ef0-5df903e5647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = BedrockChat(model_id=\"anthropic.claude-v2:1\", model_kwargs={\"temperature\": 0}, region_name='us-east-1')\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    chat_llm,\n",
    "    graph=graph_instance, \n",
    "    cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
    "    verbose=True,\n",
    "    validate_cypher=True,\n",
    "    return_direct=True\n",
    ")\n",
    "\n",
    "def chat(question):\n",
    "    r = chain(question)\n",
    "    summary_prompt_tpl = f\"\"\"Human: \n",
    "    Fact: {json.dumps(r['result'])}\n",
    "\n",
    "    * Describe the above fact as if you are answering this question \"{r['query']}\"\n",
    "    * Don't omit any information related to the question\n",
    "    * When the fact is not empty, assume the question is valid and the answer is true\n",
    "    * Do not return helpful or extra text or apologies\n",
    "    * List the results in rich text format if there are more than one results\n",
    "    Assistant:\n",
    "    \"\"\"\n",
    "    return llm(summary_prompt_tpl)\n",
    "\n",
    "def chat_response(input_text):\n",
    "    try:\n",
    "        return chat(input_text)\n",
    "    except:\n",
    "        return \"I'm sorry, there was an error retrieving the information you requested.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "33564b9a-f1cd-4ede-a02f-f2cce7db9c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "MATCH (ec2:Service {name:\"Amazon EC2\"})-[:hasStorageType]->(storage:Service)\n",
      "WITH storage \n",
      "MATCH (storage)-[:CHUNKED]->(chunk:Chunk)\n",
      "WHERE chunk.text CONTAINS \"storage\" OR chunk.text CONTAINS \"use\" OR chunk.text CONTAINS \"performance\"\n",
      "RETURN COLLECT(DISTINCT chunk.text) AS text\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Based on the facts provided, here are the details on the different storage types available for Amazon EC2:\n",
      "\n",
      "<b>Amazon Elastic Block Store (EBS)</b>\n",
      "\n",
      "EBS provides raw block-level storage that can be attached to Amazon EC2 instances. It offers two major categories of storage options:\n",
      "\n",
      "1. SSD-backed storage for transactional workloads like databases and boot volumes. Performance depends primarily on IOPS. Volume types include:\n",
      "\n",
      "- General Purpose SSD (gp2): General purpose SSD volume that balances price and performance. \n",
      "- Provisioned IOPS SSD (io1): Highest performance SSD volume designed for mission-critical applications.  \n",
      "- Throughput Optimized HDD (st1): Low cost HDD volume designed for frequently accessed, throughput intensive workloads.\n",
      "- Cold HDD (sc1): Lowest cost HDD volume designed for less frequently accessed workloads.\n",
      "\n",
      "2. Disk-backed storage for throughput intensive workloads like MapReduce and log processing. Performance depends primarily on MB/s throughput.\n",
      "\n",
      "EBS volumes can be encrypted and support features like automated snapshots, cloning, tagging, and RAID configurations.\n",
      "\n",
      "For the highest performance, Provisioned IOPS SSD (io1) is the best EBS option. It delivers low latency and the highest IOPS per volume of any EBS type.\n",
      "\n",
      "So in summary, EBS provides a range of block storage options optimized for different performance, cost, and workload requirements. The io1 volume type is best suited for applications needing maximum perfgormance.\n"
     ]
    }
   ],
   "source": [
    "chat_answer = chat(question) \n",
    "print(chat_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25da5e-d1f3-4625-895e-895157baf985",
   "metadata": {},
   "source": [
    "### -정보를 통합해서 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b17bd06e-6578-41ab-8663-912c35edb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_answer(question, fact1, fact2):\n",
    "    \n",
    "    summary_prompt_tpl = f\"\"\"Human: \n",
    "    <fact1> \n",
    "    {fact1}\n",
    "    </fact1>\n",
    "    <fact2>\n",
    "    {fact2}\n",
    "    </fact2>\n",
    "    \n",
    "    * Describe the above fact as if you are answering this question \"{question}\"\n",
    "    * Combine the multiple facts related to the question.\n",
    "    * When the fact is not empty, assume the question is valid and the answer is true\n",
    "    * Do not return helpful or extra text or apologies\n",
    "    * List the results in rich text format if there are more than one results\n",
    "    Assistant:\n",
    "    \"\"\"\n",
    "    return llm(summary_prompt_tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4f02bc48-ae60-42cd-bfc3-58e398dd8ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is the detailed information on the different storage types available for Amazon EC2:\n",
      "\n",
      "<b>Instance Store Volumes</b>\n",
      "- Temporary block-level storage volumes\n",
      "- Persist only during the EC2 instance lifetime \n",
      "- Data lost when instance is stopped or terminated\n",
      "- Use Cases: \n",
      "    - Buffers, caches, scratch data\n",
      "    - Not suitable for persistent data\n",
      "\n",
      "<b>Elastic Block Store (EBS) Volumes</b> \n",
      "- Persistent block storage volumes \n",
      "- Data persists independently from EC2 instance\n",
      "- Can be up to 16 TB in size\n",
      "- Data persists when instance is stopped/terminated\n",
      "- Use Cases:\n",
      "    - Databases, application data \n",
      "    - Great for persistent storage\n",
      "\n",
      "<b>EBS Volume Types</b>\n",
      "1. SSD-backed storage \n",
      "    - General Purpose SSD (gp2): Balances price and performance\n",
      "    - Provisioned IOPS SSD (io1): Highest performance SSD for mission-critical applications\n",
      "2. Disk-backed storage\n",
      "    - Throughput Optimized HDD (st1): Frequently accessed, throughput intensive workloads \n",
      "    - Cold HDD (sc1): Less frequently accessed workloads\n",
      "\n",
      "Key EBS Features:\n",
      "- Volumes can be detached/attached across EC2 instances\n",
      "- Support snapshots and clones\n",
      "- Replicated storage for high availability \n",
      "- RAID configurations\n",
      "\n",
      "<b>For highest performance</b>, Provisioned IOPS SSD (io1) delivers the lowest latency and highest IOPS per volume of any EBS type.\n",
      "\n",
      "So in summary, EBS provides a range of persistent block storage options optimized for different performance, cost and workload requirements. The io1 volume type is best suited for applications needing maximum performance.\n"
     ]
    }
   ],
   "source": [
    "facts = {\n",
    "    \"fact1\": vector_answer,\n",
    "    \"fact2\": chat_answer\n",
    "}\n",
    "final_answer = summarize_answer(question, vector_answer, chat_answer)\n",
    "print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
